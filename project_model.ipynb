{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIkPB-0-iq3J"
   },
   "source": [
    "Our dataset consists of 1 image (using ESP32-CAM, prob 800 X 600), 1 temperature reading, 1 humidity reading, 1 barometric reading, and 1 wind speed reading.\n",
    "Output data will be whether it is raining at the timestep of the next 5 minutes.\n",
    "A CNN model will be used for the image, then the result is used as together with the sensor data in a decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIeH3I-tl_Bb"
   },
   "source": [
    "The below code is to mount to google drive for loading and saving purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3212,
     "status": "ok",
     "timestamp": 1731313176890,
     "user": {
      "displayName": "Noah Liu",
      "userId": "00198293930937973959"
     },
     "user_tz": -480
    },
    "id": "9dxvKIyDispz",
    "outputId": "24eac2f5-39b4-4212-862a-8e5f70df8238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1731313499050,
     "user": {
      "displayName": "Noah Liu",
      "userId": "00198293930937973959"
     },
     "user_tz": -480
    },
    "id": "L6Y-corUj21C"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/CS3237_ML_Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1731313499852,
     "user": {
      "displayName": "Noah Liu",
      "userId": "00198293930937973959"
     },
     "user_tz": -480
    },
    "id": "_-TELvY-kR72"
   },
   "outputs": [],
   "source": [
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code below is for the CNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddSEq05LDS47"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = (128, 128)\n",
    "num_classes = 6\n",
    "batch_size = 50\n",
    "epochs = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 12799,
     "status": "error",
     "timestamp": 1731308762868,
     "user": {
      "displayName": "Noah Liu",
      "userId": "00198293930937973959"
     },
     "user_tz": -480
    },
    "id": "1aTHHs3Dow2a",
    "outputId": "eded1413-bfb9-41a9-f9bc-05bcd94402e3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e4a7c906f6c7>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Data transform for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m transform = transforms.Compose([\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_size' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "classes = (\"A-Clear Sky\", \"B-Patterned Clouds\", \"C-Thin White Clouds\", \"D-Thick White Clouds\", \"E-Thick Dark Clouds\", \"F-Veil Clouds\")\n",
    "\n",
    "# Data transform for training\n",
    "transform = transforms.Compose([\n",
    "  transforms.Resize(input_size),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "  transforms.RandomHorizontalFlip(),\n",
    "  transforms.RandomRotation(15),\n",
    "])\n",
    "\n",
    "# Load data\n",
    "train_data = datasets.ImageFolder(root='Dataset2/train', transform=transform)\n",
    "test_data = datasets.ImageFolder(root='Dataset2/test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qov4pUcUDJEy"
   },
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class WeatherModel(nn.Module):\n",
    "  def __init__(self, num_classes):\n",
    "    super(WeatherModel, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "    self.pool = nn.MaxPool2d(2, 2)\n",
    "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "    self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "    self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "    self.fc1 = nn.Linear(128 * 8 * 8, 256)\n",
    "    self.dropout = nn.Dropout(0.5)\n",
    "    self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.pool(torch.relu(self.conv1(x)))\n",
    "    x = self.pool(torch.relu(self.conv2(x)))\n",
    "    x = self.pool(torch.relu(self.conv3(x)))\n",
    "    x = self.pool(torch.relu(self.conv4(x)))\n",
    "\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = torch.relu(self.fc1(x))\n",
    "    x = self.dropout(x)\n",
    "    x = self.fc2(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2847847,
     "status": "ok",
     "timestamp": 1730211316905,
     "user": {
      "displayName": "Green Tea",
      "userId": "04033900127904214290"
     },
     "user_tz": -480
    },
    "id": "BXUgj_6ADdI1",
    "outputId": "422074e0-10bf-42a4-a03f-478f116a95dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Training Loss: 40.79841464757919  Test Loss: 5.637934118509293\n",
      "Epoch 1 Training Loss: 27.446874856948853  Test Loss: 4.113233186304569\n",
      "Epoch 2 Training Loss: 22.56625720858574  Test Loss: 3.5691803842782974\n",
      "Epoch 3 Training Loss: 18.6502425968647  Test Loss: 2.842763312160969\n",
      "Epoch 4 Training Loss: 14.975115582346916  Test Loss: 2.7511617336422205\n",
      "Epoch 5 Training Loss: 13.802535817027092  Test Loss: 2.5490060755982995\n",
      "Epoch 6 Training Loss: 9.011527478694916  Test Loss: 1.957669073715806\n",
      "Epoch 7 Training Loss: 9.589469268918037  Test Loss: 2.089536768384278\n",
      "Epoch 8 Training Loss: 7.805121347308159  Test Loss: 1.7476374595426023\n",
      "Epoch 9 Training Loss: 7.357932902872562  Test Loss: 1.7223176965489984\n",
      "Epoch 10 Training Loss: 6.694688588380814  Test Loss: 1.5368231385946274\n",
      "Epoch 11 Training Loss: 6.192168101668358  Test Loss: 1.4252266734838486\n",
      "Epoch 12 Training Loss: 5.071500509977341  Test Loss: 1.5087617486715317\n",
      "Epoch 13 Training Loss: 5.456499453634024  Test Loss: 1.3532852958887815\n",
      "Epoch 14 Training Loss: 5.963291980326176  Test Loss: 1.9512059148401022\n",
      "Epoch 15 Training Loss: 4.636995892971754  Test Loss: 1.440651305951178\n",
      "Epoch 16 Training Loss: 3.9562267512083054  Test Loss: 1.5581292267888784\n",
      "Epoch 17 Training Loss: 3.7337815407663584  Test Loss: 1.3244830872863531\n",
      "Epoch 18 Training Loss: 3.855825051665306  Test Loss: 1.1846500146202743\n",
      "Epoch 19 Training Loss: 3.0466791708022356  Test Loss: 0.9925634413957596\n",
      "Epoch 20 Training Loss: 3.5954894204623997  Test Loss: 1.8836550936102867\n",
      "Epoch 21 Training Loss: 2.7562023838981986  Test Loss: 1.117229349911213\n",
      "Epoch 22 Training Loss: 4.316446488723159  Test Loss: 2.215683461356093\n",
      "Epoch 23 Training Loss: 3.444433329626918  Test Loss: 1.1004393063485622\n",
      "Epoch 24 Training Loss: 1.7461233120411634  Test Loss: 1.1940350830554962\n",
      "Epoch 25 Training Loss: 2.260797156020999  Test Loss: 1.2004894313868135\n",
      "Epoch 26 Training Loss: 3.1002821940928698  Test Loss: 1.407353434478864\n",
      "Epoch 27 Training Loss: 1.7314366444479674  Test Loss: 1.1985407350584865\n",
      "Epoch 28 Training Loss: 1.5666962240356952  Test Loss: 1.4261392907937989\n",
      "Epoch 29 Training Loss: 3.215434990124777  Test Loss: 1.1822314066812396\n",
      "Epoch 30 Training Loss: 1.1661515864543617  Test Loss: 1.3022704715840518\n",
      "Epoch 31 Training Loss: 0.9751795562915504  Test Loss: 1.1053060367703438\n",
      "Epoch 32 Training Loss: 1.7291071764193475  Test Loss: 1.1417186008766294\n",
      "Epoch 33 Training Loss: 1.3402358309249394  Test Loss: 1.004716063151136\n",
      "Epoch 34 Training Loss: 1.0642968777101487  Test Loss: 1.8042833795771003\n",
      "Epoch 35 Training Loss: 3.4712728227023035  Test Loss: 2.4492185208946466\n",
      "Epoch 36 Training Loss: 3.182405086234212  Test Loss: 1.6097544189542532\n",
      "Epoch 37 Training Loss: 1.505157196545042  Test Loss: 1.420293512986973\n",
      "Epoch 38 Training Loss: 1.4178256010636687  Test Loss: 1.1376357341650873\n",
      "Epoch 39 Training Loss: 1.9840002707205713  Test Loss: 1.4675930440425873\n",
      "Epoch 40 Training Loss: 1.676995791029185  Test Loss: 1.159830579534173\n",
      "Epoch 41 Training Loss: 1.4438306228257716  Test Loss: 1.7980003021657467\n",
      "Epoch 42 Training Loss: 1.258023307309486  Test Loss: 1.0971101751783863\n",
      "Epoch 43 Training Loss: 0.5317512384499423  Test Loss: 1.2044932078570127\n",
      "Epoch 44 Training Loss: 1.601235085283406  Test Loss: 2.2378317043185234\n",
      "Epoch 45 Training Loss: 2.66117069683969  Test Loss: 1.4948810070054606\n",
      "Epoch 46 Training Loss: 1.3596960175782442  Test Loss: 1.3092585189733654\n",
      "Epoch 47 Training Loss: 1.4080430699978024  Test Loss: 1.761570619419217\n",
      "Epoch 48 Training Loss: 0.9541115680476651  Test Loss: 2.560459552332759\n",
      "Epoch 49 Training Loss: 0.7146964026615024  Test Loss: 1.8966232297825627\n",
      "Epoch 50 Training Loss: 1.2097259409492835  Test Loss: 1.3005817401244713\n",
      "Epoch 51 Training Loss: 1.0864886139170267  Test Loss: 1.420098023081664\n",
      "Epoch 52 Training Loss: 1.8980396410916  Test Loss: 2.2670114734210074\n",
      "Epoch 53 Training Loss: 1.223090206971392  Test Loss: 1.408513282891363\n",
      "Epoch 54 Training Loss: 1.2215641741931904  Test Loss: 1.24184236516885\n",
      "Epoch 55 Training Loss: 0.633787965925876  Test Loss: 1.8815762273734435\n",
      "Epoch 56 Training Loss: 0.6554066134121967  Test Loss: 1.7366427303641103\n",
      "Epoch 57 Training Loss: 1.738114730338566  Test Loss: 2.0639432929456234\n",
      "Epoch 58 Training Loss: 0.822588455863297  Test Loss: 1.4232670849160058\n",
      "Epoch 59 Training Loss: 0.5522682803857606  Test Loss: 1.4489397318618558\n",
      "Epoch 60 Training Loss: 0.4574618717779231  Test Loss: 2.424464654381154\n",
      "Epoch 61 Training Loss: 0.7751552119734697  Test Loss: 1.7655369099229574\n",
      "Epoch 62 Training Loss: 0.7876885220466647  Test Loss: 1.3600568147958256\n",
      "Epoch 63 Training Loss: 0.510652339173248  Test Loss: 2.516071015386842\n",
      "Epoch 64 Training Loss: 0.3870260739568039  Test Loss: 1.5930642019957304\n",
      "Epoch 65 Training Loss: 0.6245593963540159  Test Loss: 1.818436688859947\n",
      "Epoch 66 Training Loss: 1.355784220068017  Test Loss: 1.9973098943009973\n",
      "Epoch 67 Training Loss: 1.0989385361608583  Test Loss: 1.9367547971196473\n",
      "Epoch 68 Training Loss: 0.631274436833337  Test Loss: 2.460457013672567\n",
      "Epoch 69 Training Loss: 0.9023868031508755  Test Loss: 1.4338173789001303\n",
      "Epoch 70 Training Loss: 1.1625748401856981  Test Loss: 1.605052128317766\n",
      "Epoch 71 Training Loss: 0.671002775139641  Test Loss: 1.8115919595857122\n",
      "Epoch 72 Training Loss: 0.25465955333493184  Test Loss: 2.403272807438043\n",
      "Epoch 73 Training Loss: 0.8298561360425083  Test Loss: 1.952648924663663\n",
      "Epoch 74 Training Loss: 1.1146169638377614  Test Loss: 2.6225783633999527\n",
      "Epoch 75 Training Loss: 2.8823826464358717  Test Loss: 2.0366936456412077\n",
      "Epoch 76 Training Loss: 0.5995896307867952  Test Loss: 3.2770271887420677\n",
      "Epoch 77 Training Loss: 0.7499768160050735  Test Loss: 1.9437192808836699\n",
      "Epoch 78 Training Loss: 0.6558010449807625  Test Loss: 2.0426421586453216\n",
      "Epoch 79 Training Loss: 0.6760495406924747  Test Loss: 2.042618613690138\n",
      "Epoch 80 Training Loss: 0.6032150211940461  Test Loss: 2.2832026416435838\n",
      "Epoch 81 Training Loss: 0.8122852868691552  Test Loss: 2.7237475726069533\n",
      "Epoch 82 Training Loss: 0.24820056004682556  Test Loss: 2.1330112784307858\n",
      "Epoch 83 Training Loss: 0.29159059649100527  Test Loss: 2.6245131745090475\n",
      "Epoch 84 Training Loss: 0.21793823665211676  Test Loss: 1.8481607616831752\n",
      "Epoch 85 Training Loss: 0.2620569821665413  Test Loss: 2.427980228945671\n",
      "Epoch 86 Training Loss: 0.21776060369825245  Test Loss: 1.9931416361650918\n",
      "Epoch 87 Training Loss: 1.8800224154620082  Test Loss: 2.0968541018664837\n",
      "Epoch 88 Training Loss: 2.780767080388614  Test Loss: 2.496036432558867\n",
      "Epoch 89 Training Loss: 4.376537647098303  Test Loss: 1.6333705979559454\n",
      "Epoch 90 Training Loss: 1.345605303067714  Test Loss: 1.5263321021338925\n",
      "Epoch 91 Training Loss: 0.608461113908561  Test Loss: 2.4612648118054494\n",
      "Epoch 92 Training Loss: 0.9239038430969231  Test Loss: 2.0270261764926545\n",
      "Epoch 93 Training Loss: 1.0598453870152298  Test Loss: 2.2719467754795915\n",
      "Epoch 94 Training Loss: 1.41289297840558  Test Loss: 1.0805200480936037\n",
      "Epoch 95 Training Loss: 0.49102058832067996  Test Loss: 1.4497950188815594\n",
      "Epoch 96 Training Loss: 0.20292396502918564  Test Loss: 2.0880412246206106\n",
      "Epoch 97 Training Loss: 0.39640400605276227  Test Loss: 3.2759530026050925\n",
      "Epoch 98 Training Loss: 2.7550635055231396  Test Loss: 2.1784295636516617\n",
      "Epoch 99 Training Loss: 2.604220876004547  Test Loss: 1.9781031236052513\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = WeatherModel(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "  running_loss = 0.0\n",
    "  validation_loss = 0.0\n",
    "  for images, labels in train_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    train_outputs = model(images)\n",
    "    train_loss = criterion(train_outputs, labels)\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += train_loss.item()\n",
    "  for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    test_outputs = model(images)\n",
    "    test_loss = criterion(test_outputs, labels)\n",
    "    validation_loss += test_loss.item()\n",
    "  print(\"Epoch\", epoch, \"Training Loss:\", running_loss, \" Test Loss:\", validation_loss)\n",
    "torch.save(model.state_dict(), 'WeatherModel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1730270819768,
     "user": {
      "displayName": "Green Tea",
      "userId": "04033900127904214290"
     },
     "user_tz": -480
    },
    "id": "gqu9rQjmIcP-",
    "outputId": "9717856a-0607-4221-c065-4a5bdc38c044"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-85359f141b1f>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"WeatherModel.pth\", map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = WeatherModel(num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load(\"WeatherModel.pth\", map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 417952,
     "status": "ok",
     "timestamp": 1730271240284,
     "user": {
      "displayName": "Green Tea",
      "userId": "04033900127904214290"
     },
     "user_tz": -480
    },
    "id": "itlt6jVqc_p7",
    "outputId": "7a878de2-12b4-4f7e-8d7b-b885e7b217bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy of A-Clear Sky: 100% (300/300)\n",
      "Train Accuracy of B-Patterned Clouds: 100% (300/300)\n",
      "Train Accuracy of C-Thin White Clouds: 99% (299/300)\n",
      "Train Accuracy of D-Thick White Clouds: 99% (297/300)\n",
      "Train Accuracy of E-Thick Dark Clouds: 99% (299/300)\n",
      "Train Accuracy of F-Veil Clouds: 100% (300/300)\n",
      "\n",
      "Train Accuracy (Overall): 99% (1795/1800)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "class_correct = list(0. for i in range(num_classes))\n",
    "class_total = list(0. for i in range(num_classes))\n",
    "with torch.no_grad():\n",
    "  for images, labels in train_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(len(labels)):\n",
    "      label = labels[i]\n",
    "      class_correct[label] += c[i].item()\n",
    "      class_total[label] += 1\n",
    "\n",
    "for i in range(num_classes):\n",
    "  print('Train Accuracy of %5s: %2d%% (%2d/%2d)' % (classes[i], 100.0 * class_correct[i] / class_total[i], class_correct[i], class_total[i]))\n",
    "\n",
    "print('\\nTrain Accuracy (Overall): %2d%% (%2d/%2d)' % (100.0 * sum(class_correct) / sum(class_total), sum(class_correct), sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1805,
     "status": "ok",
     "timestamp": 1730213778796,
     "user": {
      "displayName": "Green Tea",
      "userId": "04033900127904214290"
     },
     "user_tz": -480
    },
    "id": "zVIZv9S0Db0m",
    "outputId": "5b8604a1-9b6c-4cf6-c81a-a4612d8dcbca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of A-Clear Sky: 98% (49/50)\n",
      "Test Accuracy of B-Patterned Clouds: 98% (49/50)\n",
      "Test Accuracy of C-Thin White Clouds: 94% (47/50)\n",
      "Test Accuracy of D-Thick White Clouds: 86% (43/50)\n",
      "Test Accuracy of E-Thick Dark Clouds: 100% (50/50)\n",
      "Test Accuracy of F-Veil Clouds: 96% (48/50)\n",
      "\n",
      "Test Accuracy (Overall): 95% (286/300)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "class_correct = list(0. for i in range(num_classes))\n",
    "class_total = list(0. for i in range(num_classes))\n",
    "with torch.no_grad():\n",
    "  for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(len(labels)):\n",
    "      label = labels[i]\n",
    "      class_correct[label] += c[i].item()\n",
    "      class_total[label] += 1\n",
    "\n",
    "for i in range(num_classes):\n",
    "  print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (classes[i], 100.0 * class_correct[i] / class_total[i], class_correct[i], class_total[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (100.0 * sum(class_correct) / sum(class_total), sum(class_correct), sum(class_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the decision tree training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1731313504562,
     "user": {
      "displayName": "Noah Liu",
      "userId": "00198293930937973959"
     },
     "user_tz": -480
    },
    "id": "ncH85fhLaEow",
    "outputId": "5b1833b7-1f3c-4fe4-b9bf-459c9c3fe772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.9583333333333334\n",
      "Decision Tree: \n",
      "|--- 2 <= 28.90\n",
      "|   |--- 5 <= 93.50\n",
      "|   |   |--- 4 <= 24.45\n",
      "|   |   |   |--- 3 <= 100861.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- 3 >  100861.50\n",
      "|   |   |   |   |--- 1 <= 0.84\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- 1 >  0.84\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |--- 4 >  24.45\n",
      "|   |   |   |--- 2 <= 26.15\n",
      "|   |   |   |   |--- 4 <= 24.85\n",
      "|   |   |   |   |   |--- 3 <= 100812.00\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- 3 >  100812.00\n",
      "|   |   |   |   |   |   |--- 3 <= 100818.00\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 3 >  100818.00\n",
      "|   |   |   |   |   |   |   |--- 3 <= 100820.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 3 >  100820.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- 4 >  24.85\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- 2 >  26.15\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |--- 5 >  93.50\n",
      "|   |   |--- 1 <= 0.56\n",
      "|   |   |   |--- 1 <= 0.12\n",
      "|   |   |   |   |--- 2 <= 25.75\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- 2 >  25.75\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- 1 >  0.12\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- 1 >  0.56\n",
      "|   |   |   |--- 4 <= 24.15\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- 4 >  24.15\n",
      "|   |   |   |   |--- class: 0\n",
      "|--- 2 >  28.90\n",
      "|   |--- class: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import export_text\n",
    "import pickle\n",
    "\n",
    "# Load collected data (processed in DecisionTree.ipynb)\n",
    "torch_data_5a = torch.load(\"dataset_11_5a.pt\", weights_only=True)\n",
    "target_data_5a = torch.load(\"target_11_5a.pt\", weights_only=True)\n",
    "\n",
    "X_5a = pd.DataFrame(torch_data_5a)\n",
    "y_5a = pd.DataFrame(target_data_5a)\n",
    "# X_5a.columns = ['cloudClass', 'windSpeed', 'bmpTemp', 'bmpPressure', 'dhtTemp', 'dhtHumidity']\n",
    "X_5a.drop(X_5a.tail(5).index, inplace=True)\n",
    "y_5a.drop(y_5a.head(5).index, inplace=True)\n",
    "\n",
    "torch_data_5b = torch.load(\"dataset_11_5b.pt\", weights_only=True)\n",
    "target_data_5b = torch.load(\"target_11_5b.pt\", weights_only=True)\n",
    "\n",
    "X_5b = pd.DataFrame(torch_data_5b)\n",
    "y_5b = pd.DataFrame(target_data_5b)\n",
    "# X_5b.columns = ['cloudClass', 'windSpeed', 'bmpTemp', 'bmpPressure', 'dhtTemp', 'dhtHumidity']\n",
    "X_5b.drop(X_5b.tail(5).index, inplace=True)\n",
    "y_5b.drop(y_5b.head(5).index, inplace=True)\n",
    "\n",
    "X = pd.concat([X_5a, X_5b], ignore_index=True)\n",
    "y = pd.concat([y_5a, y_5b], ignore_index=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, shuffle=True)\n",
    "\n",
    "# Train decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "with open('decision_tree.pkl', 'wb') as file:\n",
    "  pickle.dump(clf, file)\n",
    "\n",
    "# Evaluate model\n",
    "y_train_pred = clf.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "tree_rules = export_text(clf, feature_names=X.columns[0:])\n",
    "print(f\"Decision Tree: \\n{tree_rules}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1731313509209,
     "user": {
      "displayName": "Noah Liu",
      "userId": "00198293930937973959"
     },
     "user_tz": -480
    },
    "id": "1j43kxFFLySV",
    "outputId": "d99f48ee-2e23-4890-bada-bf86c8e61cac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: \n",
      "|--- 2 <= 28.90\n",
      "|   |--- 5 <= 93.50\n",
      "|   |   |--- 4 <= 24.45\n",
      "|   |   |   |--- 3 <= 100861.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- 3 >  100861.50\n",
      "|   |   |   |   |--- 1 <= 0.84\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- 1 >  0.84\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |--- 4 >  24.45\n",
      "|   |   |   |--- 2 <= 26.15\n",
      "|   |   |   |   |--- 4 <= 24.85\n",
      "|   |   |   |   |   |--- 3 <= 100812.00\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- 3 >  100812.00\n",
      "|   |   |   |   |   |   |--- 3 <= 100818.00\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 3 >  100818.00\n",
      "|   |   |   |   |   |   |   |--- 3 <= 100820.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 3 >  100820.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- 4 >  24.85\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- 2 >  26.15\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |--- 5 >  93.50\n",
      "|   |   |--- 1 <= 0.56\n",
      "|   |   |   |--- 1 <= 0.12\n",
      "|   |   |   |   |--- 2 <= 25.75\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- 2 >  25.75\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- 1 >  0.12\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- 1 >  0.56\n",
      "|   |   |   |--- 4 <= 24.15\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- 4 >  24.15\n",
      "|   |   |   |   |--- class: 0\n",
      "|--- 2 >  28.90\n",
      "|   |--- class: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('decision_tree.pkl', 'rb') as file:\n",
    "  clf = pickle.load(file)\n",
    "  tree_rules = export_text(clf, feature_names=X.columns[0:])\n",
    "  print(f\"Decision Tree: \\n{tree_rules}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
